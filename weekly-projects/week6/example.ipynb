{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f30f15-5f5b-466b-b6a5-8da43f2781da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82672da-8e12-4332-9dd7-4b9c32846500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "\n",
    "# Define an array transformation that transforms the images to tensor format \n",
    "# and normalizes the pixel values to the range [-1, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Download and load the training and test datasets\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, \n",
    "    download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, \n",
    "    download=True, transform=transform)\n",
    "\n",
    "# Split the training dataset into a training set and a validation set\n",
    "train_set, val_set = random_split(train_dataset, [50000, 10000])\n",
    "\n",
    "# Create data loaders for the training, validation, and test sets\n",
    "# A DataLoader in PyTorch is an object that simplifies and automates\n",
    "# batching, shuffling, and loading data for model training and evaluation. \n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e1bf0-f224-4e28-a8c4-583152f26f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN architecture\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A Convolutional Neural Network (CNN) for classifying MNIST images.\n",
    "    \n",
    "    The network consists of a feature extraction architecture and a \n",
    "    classification architecture. The feature-extraction architecture includes\n",
    "    two convolutional layers. Each of the convolutional layers is followed by \n",
    "    a sigmoid activation and a max pooling layer. The classification \n",
    "    architecture includes two fully connected layers for classification.\n",
    "\n",
    "    Attributes:\n",
    "    conv1 : torch.nn.Conv2d\n",
    "        The first convolutional layer\n",
    "    conv2 : torch.nn.Conv2d\n",
    "        The second convolutional layer\n",
    "    activation : torch.nn activation function\n",
    "        Activation function used for input and hidden layers\n",
    "    pool : torch.nn.MaxPool2d\n",
    "        The pooling layer\n",
    "    fc1 : torch.nn.Linear\n",
    "        The first fully connected layer\n",
    "    fc2 : torch.nn.Linear\n",
    "        The second fully connected layer\n",
    "\n",
    "    Methods:\n",
    "    __init__(self): \n",
    "        This function creates an instance of this class.\n",
    "    forward(self, x):\n",
    "        Performs a forward pass for an input x.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the CNN model by defining its layers.\n",
    "        \"\"\"\n",
    "        # Create an instance of the parent class `nn.Module`\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # `self.name = object` creates an attribute with the name `name` for \n",
    "        # our the newly created instance of our class, and it assigns that\n",
    "        # attribute the value `object`. Example: For your first homework, you\n",
    "        # could have create a class `TicTacToe`. Adding the line \n",
    "        # `self.is_game_over = False` to the instance-initialization function\n",
    "        # of that class would ensure that everytime a new game of TicTacToe is \n",
    "        # initialized, it would have an attribute `is_game_over` and initially\n",
    "        # the value of that attribute would be `False`. \n",
    "        # Here, we use the class-attribute syntax to create layers for our CNN.\n",
    "        \n",
    "        # Define the first convolutional layer. It uses a 8 filters of size \n",
    "        # 3-by-3 to turn a 1-channel image into an 8-channel image.         \n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)\n",
    "\n",
    "        # The MNIST images are grayscale images. Therefore, the input data for\n",
    "        # out CNN has only one channel. Color images typically come with three\n",
    "        # channels: a red channel, a green channel, and a blue channel. \n",
    "        # Throughout the feature extraction, the number of channels typically \n",
    "        # changes quite drastically. The channels of the transformed features\n",
    "        # typically do not correspond to colors anymore. Instead, different\n",
    "        # channels of the transformed image contain different information about\n",
    "        # the original image. For example, a channel created by applying an\n",
    "        # edge-detection filter would have information about the locations of \n",
    "        # sharp edges. A channel created by applying a blur filter would have\n",
    "        # information about the coarse-grained distribution of light and dark\n",
    "        # patches.\n",
    "        \n",
    "        # Define the second convolutional layer. It uses 16 filters of size \n",
    "        # 3-by-3 to turn a 8-channel image into an 16-channel image.\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        # Define the activation function\n",
    "        self.activation = nn.Sigmoid()\n",
    "        # Define a pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        # Define a fully connected layer hidden with 128 nodes\n",
    "        # Inputs are num_channels in previous layer x image height x image width\n",
    "        self.fc1 = nn.Linear(16 * 8 * 8, 128)\n",
    "        # Define the output layer with 10 nodes\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define the forward pass of the CNN.\n",
    "\n",
    "        Parameters:\n",
    "        x : torch.Tensor\n",
    "            The input tensor containing the image batch.\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor\n",
    "            The output tensor containing the class scores for each image.\n",
    "        \"\"\"\n",
    "        # Pass the input through the first convolutional layer, then apply activation\n",
    "        x = self.activation(self.conv1(x))\n",
    "        # Pass the input through the first pooling layer\n",
    "        x = self.pool(x)\n",
    "        # Pass the input through the second convolutional layer, then apply activation\n",
    "        x = self.activation(self.conv2(x))\n",
    "        # Pass the input through the second pooling layer\n",
    "        x = self.pool(x)     \n",
    "        # Change the shape of x into a 1d array\n",
    "        x = x.view(-1, 16 * 8 * 8)\n",
    "        # Pass the input through the full connected hidden layer, then apply activation\n",
    "        x = self.activation(self.fc1(x))\n",
    "        # Pass the input through the last layer\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b857ffa5-fcb2-493d-8478-429ad0392559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training pipeline including validation after each epoch\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    \"\"\"\n",
    "    Train the CNN model.\n",
    "\n",
    "    Parameters:\n",
    "    model : torch.nn.Module\n",
    "        The CNN model to be trained.\n",
    "    train_loader : torch.utils.data.DataLoader\n",
    "        The data loader for the training set.\n",
    "    val_loader : torch.utils.data.DataLoader\n",
    "        The data loader for the validation set.\n",
    "    criterion : torch.nn.modules.loss._Loss\n",
    "        The loss function to be used.\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        The optimizer to be used.\n",
    "    epochs : int\n",
    "        The number of epochs for training.\n",
    "\n",
    "    Returns:\n",
    "    tuple\n",
    "        A tuple containing lists of training loss, validation loss, training accuracy, and validation accuracy.\n",
    "    \"\"\"\n",
    "    # Initialize lists to store training and validation loss\n",
    "    train_loss, val_loss = [], []\n",
    "    # Initialize lists to store training and validation and accuracy\n",
    "    train_acc, val_acc = [], []\n",
    "\n",
    "    # Loop over the number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        # Set the model to training mode\n",
    "        model.train()  \n",
    "        # Initialize the running loss for the epoch\n",
    "        running_loss = 0.0  \n",
    "        # Initialize counters for correct predictions and total samples\n",
    "        correct, total = 0, 0  \n",
    "\n",
    "        # Learning algorithm is SGD with minibatch. Iterating over the dataload\n",
    "        # returns images and labels in batches.\n",
    "        \n",
    "        # Iterate over batches of training data\n",
    "        for images, labels in train_loader:\n",
    "            # Zero the gradients to prevent accumulation from previous iterations\n",
    "            optimizer.zero_grad()  \n",
    "            # Perform a forward pass through the model to get predictions\n",
    "            outputs = model(images)  \n",
    "            # Compute the loss between predictions and true labels\n",
    "            loss = criterion(outputs, labels)  \n",
    "            # Perform a backward pass to compute gradients via backpropagation\n",
    "            loss.backward()  \n",
    "            # Update model parameters based on the computed gradients\n",
    "            optimizer.step()  \n",
    "\n",
    "            # Add up the loss\n",
    "            running_loss += loss.item()  \n",
    "            # Get the predicted class with the highest score\n",
    "            _, predicted = torch.max(outputs.data, 1)  \n",
    "            # Update the total number of samples\n",
    "            total += labels.size(0)  \n",
    "            # Update the number of correct predictions\n",
    "            correct += (predicted == labels).sum().item()  \n",
    "\n",
    "        # Compute and store the average training loss for the epoch\n",
    "        train_loss.append(running_loss / len(train_loader))  \n",
    "        # Compute and store the training accuracy for the epoch\n",
    "        train_acc.append(100 * correct / total)  \n",
    "\n",
    "        # Set the model to evaluation mode\n",
    "        model.eval()  \n",
    "        # Initialize the running loss for validation\n",
    "        val_running_loss = 0.0  \n",
    "        #  Initialize counters for correct predictions and total samples in validation\n",
    "        val_correct, val_total = 0, 0  \n",
    "        \n",
    "        # Disable gradient calculation for validation to save memory and computation\n",
    "        with torch.no_grad():\n",
    "            # Iterate over batches of validation data\n",
    "            for images, labels in val_loader:\n",
    "                # Perform a forward pass through the model to get predictions\n",
    "                outputs = model(images)  \n",
    "                # Compute the loss between predictions and true labels\n",
    "                loss = criterion(outputs, labels)  \n",
    "                # Add up the loss\n",
    "                val_running_loss += loss.item()  \n",
    "                # Get the predicted class with the highest score\n",
    "                _, predicted = torch.max(outputs.data, 1)  \n",
    "                # Update the total number of samples in validation\n",
    "                val_total += labels.size(0)  \n",
    "                # Update the number of correct predictions in validation\n",
    "                val_correct += (predicted == labels).sum().item()  \n",
    "\n",
    "        # Compute and store the average validation loss for the epoch\n",
    "        val_loss.append(val_running_loss / len(val_loader))\n",
    "        # Compute and store the validation accuracy for the epoch\n",
    "        val_acc.append(100 * val_correct / val_total)  \n",
    "        \n",
    "        # Print the results for the current epoch, including training and validation loss and accuracy\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {running_loss / len(train_loader):.4f}, '\n",
    "              f'Validation Loss: {val_running_loss / len(val_loader):.4f}, '\n",
    "              f'Train Acc: {100 * correct / total:.2f}%, Val Acc: {100 * val_correct / val_total:.2f}%')\n",
    "        \n",
    "    # Return the lists of training and validation loss and accuracy\n",
    "    return train_loss, val_loss, train_acc, val_acc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6074c19a-026c-45f5-a7c3-dad7e1b19cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train a model\n",
    "\n",
    "# Create model\n",
    "model = CNN()\n",
    "\n",
    "# Set loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set training algorithm\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train model\n",
    "train_loss, val_loss, train_acc, val_acc = train_model(model, train_loader, val_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb779767-93fc-40c0-8aca-29637e4ce2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy/loss\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e91542d-e92a-4c44-8456-65910c63842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test set\n",
    "\n",
    "model.eval()\n",
    "test_correct, test_total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_acc = 100 * test_correct / test_total\n",
    "print(f'Test Accuracy: {test_acc:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
